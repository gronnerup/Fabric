{"cells":[{"cell_type":"code","source":["import requests\n","\n","from pyspark.sql.types import StructType, StructField, StringType\n","from bs4 import BeautifulSoup\n","from pyspark.sql.functions import *\n","\n","baseurl = \"https://learn.microsoft.com/en-us/rest/api/fabric/\""],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"25010c25-2d61-4ff2-aa54-fa753e451cb2"},{"cell_type":"code","source":["# Function to extract all articles and return the data_list\n","def extract_all_articles(data):\n","    if \"items\" in data:\n","        return extract_articles(data[\"items\"])\n","    return []\n","\n","### Function for extracting \n","def extract_articles(items, level=0, path=\"\"):\n","    indent = '    ' * level  # Create indentation based on the current level\n","    local_data_list = []  # Initialize a local list to store data    \n","    \n","    for item in items:\n","        if item[\"toc_title\"] != \"Overview\":\n","            \n","            if \"href\" in item and \"toc_title\" in item:\n","                print(f\"{indent}{item['toc_title']} : {item['href']}\")\n","        \n","                article = requests.get(baseurl+item['href'])\n","                soup = BeautifulSoup(article.content, 'html.parser')\n","                identity_header = soup.find(id='microsoft-entra-supported-identities')\n","                \n","                if identity_header is not None:\n","                    rows = soup.find(id='microsoft-entra-supported-identities').find_next('table').find('tbody').find_all('tr')\n","\n","                    key_value_pairs = {}\n","                    for row in rows:\n","                        columns = row.find_all('td')\n","                        key_value_pairs[columns[0].get_text(strip=True)] = columns[1].get_text(strip=True)\n","\n","                        #To add individual rows for each identity type use the codeline below.\n","                        #local_data_list.append((path, item['toc_title'], baseurl+item['href'], item['href'],columns[0].get_text(strip=True),columns[1].get_text(strip=True)))\n","                    \n","                    local_data_list.append((path, item['toc_title'], baseurl+item['href'], item['href'],key_value_pairs.get(\"User\"),key_value_pairs.get(\"Service principalandManaged identities\")))\n","                else:\n","                    local_data_list.append((path, item['toc_title'], baseurl+item['href'], item['href'],\"N/A\",\"N/A\"))\n","            else:\n","                print(f\"{indent}{item['toc_title']}\")   \n","            if \"children\" in item:\n","                local_data_list.extend(extract_articles(item[\"children\"], level + 1, path + \"|\" + item['toc_title']))\n","    \n","    return local_data_list  # Return the local data list"],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"3715b03a-12f1-4af4-841f-511078196377"},{"cell_type":"code","source":["### Extract Fabric API documentation\n","response = requests.get(baseurl+\"toc.json\")\n","data = response.json()\n","\n","# Call the extract_all_articles function and store the return value as data_list\n","data_list = extract_all_articles(data)"],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"69fb97d5-8c04-4c31-9d7c-1ba6b653aa8a"},{"cell_type":"code","source":["### Convert the data_list to Spark DataFrame, split path and clean up\n","schema = StructType([\n","    StructField(\"Path\", StringType(), True),\n","    StructField(\"Title\", StringType(), True),\n","    StructField(\"ArticleUrl\", StringType(), True),\n","    StructField(\"Href\", StringType(), True),\n","    StructField(\"SupportUserIdentity\", StringType(), True),\n","    StructField(\"SupportSpnAndMi\", StringType(), True)\n","])\n","\n","df = spark.createDataFrame(data_list, schema)\n","\n","df = df.withColumn(\"Service\", split(df[\"Path\"], \"\\\\|\").getItem(1)) \\\n","             .withColumn(\"API\", split(df[\"Path\"], \"\\\\|\").getItem(2))\n","\n","df = df.drop(\"Path\", \"Href\")"],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"f61d9480-cc42-42f3-9ab9-bcaef8c2477a"},{"cell_type":"code","source":["### Get lakehouse if it exist otherwise create it\n","lakehouse = None\n","try:\n","    lakehouse = mssparkutils.lakehouse.get(\"FabricDocs\")\n","except:\n","    lakehouse = mssparkutils.lakehouse.create(name = \"FabricDocs\", description = \"Lakehouse for storing Microsoft Fabric documentation\")"],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"fd40bec9-78f4-4426-b4e4-b48af988a22e"},{"cell_type":"code","source":["### Write delta table\n","abfsPath = lakehouse.properties[\"abfsPath\"]\n","df.write.format(\"delta\").mode(\"overwrite\").save(f\"{abfsPath}/Tables/FabricRestApiDocs\")"],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"a36cfae0-309e-4dcf-856a-218415877090"},{"cell_type":"code","source":["### Create manual table holding Identity options\n","df_identities = spark.sql(\"\"\"\n","    SELECT \n","        1 AS IdentityNo,\n","        'User' AS Identity,\n","        'Supports user identity' AS Identity_desc,\n","        '' as IdentitySupportArticle\n","    UNION\n","    SELECT \n","        2 AS IdentityNo,\n","        'Service principal and Managed identities' AS Identity,\n","        'Supports Service principal and Managed identities' as Identity_desc,\n","        'https://learn.microsoft.com/en-us/entra/identity-platform/app-objects-and-service-principals#service-principal-object' as IdentitySupportArticle\n","\"\"\")\n","\n","df_identities.write.format(\"delta\").mode(\"overwrite\").save(f\"{abfsPath}/Tables/SupportedIdentities\")"],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"b8ea091e-b8eb-478d-aef1-81d5c581649a"},{"cell_type":"code","source":["### Download report definition file from Github\n","mssparkutils.fs.cp('https://raw.githubusercontent.com/gronnerup/Fabric/refs/heads/main/FabricRestApiDocs/report.json', f'{abfsPath}/Files')"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"efc18e77-aaf8-4fe7-992e-1b6e96cbbee7"}],"metadata":{"kernel_info":{"name":"synapse_pyspark"},"kernelspec":{"name":"synapse_pyspark","language":"Python","display_name":"Synapse PySpark"},"language_info":{"name":"python"},"microsoft":{"language":"python","language_group":"synapse_pyspark","ms_spell_check":{"ms_spell_check_language":"en"}},"widgets":{},"nteract":{"version":"nteract-front-end@1.0.0"},"synapse_widget":{"version":"0.1","state":{}},"spark_compute":{"compute_id":"/trident/default","session_options":{"conf":{"spark.synapse.nbs.session.timeout":"1200000"}}},"dependencies":{}},"nbformat":4,"nbformat_minor":5}
