{"cells":[{"cell_type":"code","source":["%pip install semantic-link-labs"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"},"jupyter":{"outputs_hidden":true}},"id":"25010c25-2d61-4ff2-aa54-fa753e451cb2"},{"cell_type":"code","source":["import sempy_labs as labs\n","from sempy_labs.directlake._get_shared_expression import get_shared_expression\n","from sempy_labs.tom import connect_semantic_model\n","from sempy_labs import report\n","import json"],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"3715b03a-12f1-4af4-841f-511078196377"},{"cell_type":"code","source":["lakehouse_name  =  \"FabricDocs\"\n","lakehouse  =  mssparkutils.lakehouse.get(lakehouse_name)\n","abfsPath = lakehouse.properties[\"abfsPath\"]\n","workspace_name  =  notebookutils.runtime.context.get(\"currentWorkspaceName\") # Get current workspace name"],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"},"tags":["parameters"]},"id":"93810d50-1809-45ff-ab88-7c737228104d"},{"cell_type":"code","source":["### Create new semantic model\n","semantic_model_name  =  f\"{lakehouse_name}_Model\"\n","labs.create_blank_semantic_model(semantic_model_name)"],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"13e07169-2522-49ba-808c-f690414417e7"},{"cell_type":"code","source":["### Add tables, columns, hierarchies and measures\n","lakehouse_workspace = lakehouse.workspaceId\n","shEx = get_shared_expression(lakehouse_name, lakehouse_workspace)\n","\n","tables = {\n","    \"FabricRestApiDocs\": {\n","        \"display_name\": \"Fabric REST APIs\",\n","        \"columns\": {\n","            \"Title\": {\"source_column\": \"Title\", \"data_type\": \"string\" },\n","            \"Service\": {\"source_column\": \"Service\", \"data_type\": \"string\" },\n","            \"API\": {\"source_column\": \"API\", \"data_type\": \"string\" },\n","            \"Article Url\": {\"source_column\": \"ArticleUrl\", \"data_type\": \"string\", \"data_category\": \"WebURL\"},\n","            \"Supports User\": {\"source_column\": \"SupportUserIdentity\", \"data_type\": \"string\" },\n","            \"Supports Service principal & Managed Identities\": {\"source_column\": \"SupportSpnAndMi\", \"data_type\": \"string\" }\n","        },\n","        \"hierarchies\" : {\n","            \"Service hierarchy\": {\"columns\": [\"Service\", \"API\", \"Title\"] }\n","        }\n","\n","    },\n","    \"SupportedIdentities\": {\n","        \"display_name\": \"Supported Identities\",\n","        \"columns\": {\n","            \"IdentityNo\": {\"source_column\": \"IdentityNo\", \"data_type\": \"integer\", \"hidden\": True },\n","            \"Identity\": {\"source_column\": \"Identity\", \"data_type\": \"string\", \"sort_by\" : \"IdentityNo\" },\n","            \"Identity Description\": {\"source_column\": \"Identity_desc\", \"data_type\": \"string\" },\n","            \"Identity Support Article Url\": {\"source_column\": \"IdentitySupportArticle\", \"data_type\": \"string\", \"data_category\": \"WebURL\" }\n","        }\n","    }\n","}\n","\n","with connect_semantic_model(dataset=semantic_model_name, readonly=False, workspace=workspace_name) as tom:\n","    if not any(e.Name == \"DatabaseQuery\" for e in tom.model.Expressions):\n","        tom.add_expression(\"DatabaseQuery\", expression=shEx)\n","        print(f\"The 'DatabaseQuery' expression has been added.\")\n","\n","    for table_name, table_data in tables.items():\n","        display_name = table_data[\"display_name\"]\n","        columns = table_data.get(\"columns\", None)\n","        hierarchies = table_data.get(\"hierarchies\", None)\n","        \n","        print(f\"Processing table: {table_name} ({display_name})\")\n","        if not any(t.Name == display_name for t in tom.model.Tables):\n","            tom.add_table(name = display_name)\n","            tom.add_entity_partition(table_name = display_name, entity_name = table_name)\n","            print(f\"The '{display_name}' table has been added.\")\n","        \n","        for column_name, attributes in columns.items():\n","            source_column = attributes[\"source_column\"]\n","            data_type = attributes[\"data_type\"]\n","            is_hidden = attributes.get(\"hidden\", False)\n","            data_category = attributes.get(\"data_category\", None)\n","            sort_by = attributes.get(\"sort_by\", None)\n","            \n","            if not any(c.Name == column_name and c.Parent.Name == display_name for c in tom.all_columns()):\n","                tom.add_data_column(\n","                    table_name = display_name,\n","                    column_name = column_name,\n","                    source_column = source_column,\n","                    hidden = is_hidden,\n","                    data_type = data_type,\n","                    data_category = data_category,\n","                )\n","                if(sort_by is not None):\n","                    tom.set_sort_by_column(table_name = display_name, column_name = column_name, sort_by_column = sort_by)\n","            \n","                print(f\"The '{source_column}' source column has been added as column '{column_name}'\")\n","\n","\n","\n","        if hierarchies is not None:\n","            for hierarchy_name, hierarchy_columns in hierarchies.items():\n","                if not any(h.Name == hierarchy_name for h in tom.all_hierarchies()):\n","                    h_columns = hierarchy_columns[\"columns\"]\n","                    tom.add_hierarchy(\n","                        table_name = display_name,\n","                        hierarchy_name = hierarchy_name,\n","                        columns = h_columns\n","    )\n","\n","    # Adding measures\n","    m_expression = \"\"\"SWITCH(\n","                        SELECTEDVALUE( 'Supported Identities'[IdentityNo] ),\n","                        1, CALCULATE( COUNTROWS( 'Fabric REST APIs' ), 'Fabric REST APIs'[Supports User] = \"Yes\" ),\n","                        2, CALCULATE( COUNTROWS( 'Fabric REST APIs' ), 'Fabric REST APIs'[Supports Service principal & Managed Identities] = \"Yes\" ),\n","                        COUNTROWS( 'Fabric REST APIs' )\n","                )\"\"\"\n","\n","    rest_api_table = tom.model.Tables[\"Fabric REST APIs\"]\n","    measure_name = \"Supported identity count\"\n","    if not any(m.Name == measure_name for m in tom.all_measures()):\n","        tom.add_measure(\n","            table_name = rest_api_table.Name, \n","            measure_name = measure_name, \n","            expression = m_expression\n","        )\n","        print(f\"The '{measure_name}' measure has been added to table '{rest_api_table.Name}'\")\n","    else:\n","        tom.update_measure(\n","            measure_name = measure_name, \n","            expression = m_expression\n","        )\n","        print(f\"The '{measure_name}' measure has been updated in table '{rest_api_table.Name}'\")\n","\n","    m_expression = \"\"\"VAR api_cnt = COUNTROWS('Fabric REST APIs')\n","        RETURN\n","            IF(\n","                [Supported identity count] - api_cnt = 0, UNICHAR( 9989 ),\n","                IF( ISBLANK([Supported identity count]), UNICHAR( 10060 ), UNICHAR( 128993 ))\n","            )\"\"\"\n","\n","    rest_api_table = tom.model.Tables[\"Supported Identities\"]\n","    measure_name = \"Identity is supported\"\n","    if not any(m.Name == measure_name for m in tom.all_measures()):\n","        tom.add_measure(\n","            table_name = rest_api_table.Name, \n","            measure_name = measure_name, \n","            expression = m_expression\n","        )\n","        print(f\"The '{measure_name}' measure has been added to table '{rest_api_table.Name}'\")\n","    else:\n","        tom.update_measure(\n","            measure_name = measure_name, \n","            expression = m_expression\n","        )\n","        print(f\"The '{measure_name}' measure has been updated in table '{rest_api_table.Name}'\")"],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"f5fecddd-f2b9-41ca-9eba-1878e6e0a416"},{"cell_type":"code","source":["# Read the file as a DataFrame where each row represents a line in the file. \n","# NOTE: Remember to attach the lakehouse containing the report.json file.\n","df = spark.read.text(f\"{abfsPath}/Files/report.json\")\n","\n","# Convert the DataFrame rows (lines) into a single string\n","json_raw = ''.join(df.rdd.map(lambda row: row[0]).collect())\n","jobject = json.loads(json_raw)\n","\n","# Create a new report based on the report.json file located in our Lakehouse\n","labs.report.create_report_from_reportjson(\n","    report = \"Fabric REST API Docs\", \n","    dataset = semantic_model_name, \n","    report_json = jobject, \n","    workspace = workspace_name\n","    )"],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"dc813b84-794a-471d-8e0f-0666533543ce"}],"metadata":{"kernel_info":{"name":"synapse_pyspark"},"kernelspec":{"name":"synapse_pyspark","language":"Python","display_name":"Synapse PySpark"},"language_info":{"name":"python"},"microsoft":{"language":"python","language_group":"synapse_pyspark","ms_spell_check":{"ms_spell_check_language":"en"}},"widgets":{},"nteract":{"version":"nteract-front-end@1.0.0"},"synapse_widget":{"version":"0.1","state":{}},"spark_compute":{"compute_id":"/trident/default","session_options":{"conf":{"spark.synapse.nbs.session.timeout":"1200000"}}},"dependencies":{"lakehouse":{}}},"nbformat":4,"nbformat_minor":5}
